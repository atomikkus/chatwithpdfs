{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'llama2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "load_dotenv() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here's one:\n",
      "\n",
      "Why don't scientists trust atoms?\n",
      "Because they make up everything!\n"
     ]
    }
   ],
   "source": [
    "model = Ollama(model=MODEL)\n",
    "embeddings = OllamaEmbeddings()\n",
    "print(model.invoke(\"Tell me a joke\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='CLINICAL PHARMACOLOGY & THERAPEUTICS | VOLUME 107 NUMBER 4 | April 2020 871An Introduction to Machine Learning\\nSolveig Badillo1,*,†, Balazs Banfai1, Fabian Birzele1, Iakov I. Davydov1, Lucy Hutchinson1, \\nT ony Kam-Thong1, Juliane Siebourg-Polster1, Bernhard Steiert1 and Jitao David Zhang1\\nIn the last few years, machine learning (ML) and artificial intelligence have seen a new wave of publicity fueled by \\nthe huge and ever-increasing amount of data and computational power as well as the discovery of improved learning algorithms. However, the idea of a computer learning some abstract concept from data and applying them to yet unseen situations is not new and has been around at least since the 1950s. Many of these basic principles are very familiar to the pharmacometrics and clinical pharmacology community. In this paper, we want to introduce the foundational ideas of ML to this community such that readers obtain the essential tools they need to understand publications on the topic. Although we will not go into the very details and theoretical background, we aim to point readers to relevant literature and put applications of ML in molecular biology as well as the fields of pharmacometrics and clinical pharmacology into perspective.\\nThe advent of data availability and growth of computational \\npower, combined with the arrival of novel learning methods, has led to a number of breakthroughs in many scientific areas. This includes biological and clinical research, where applications range from molecular biology\\n1 to image data analysis2 and clini -\\ncal practice.3 However, the idea of a computer learning some ab -\\nstract concepts—like humans do constantly—has been around at least since the 1950s when the first neural networks\\n4 were de -\\nveloped. Even before that, other methods like Bayesian statistics and Markov chains were used with a similar idea in mind. Many of these methods are known to the pharmacometrics and clini -\\ncal pharmacology community by different naming conventions. On the left, we indicate the machine learning terminology and, on the right, the usual statistics naming (based on Tibshirani https:/ /statw  eb.stanf  ord.edu/~tibs/stat3  15a/gloss  ary.pdf):\\n• network, graphs ⇔ model\\n• weights ⇔ parameters\\n• learning ⇔ fitting\\n• generalization ⇔ test set performance\\n• supervised learning ⇔ regression or classification\\n• unsupervised learning ⇔ density estimation, clustering\\n• features ⇔ covariates or explanatory variables\\nThe main difference to more traditional approaches lies very \\nmuch in the two distinct cultures of statistical modeling. This has been eluded to nearly 2\\xa0decades ago by Breiman.\\n5 Here, we extend \\nhis definition by incorporating physiological models in one of the cultures. In particular, culture 1 involves specifying a model to de -\\nscribe the observed data, and culture 2 aims to solve the problem by taking an algorithmic modeling approach, thus inherently leading to models with a higher number of free parameters and complex interactions. This complexity can pose challenges to the interpreta -\\ntion of the model (so called “black box” problem). The approaches typically used in pharmacometric applications fall into culture 1, where an underlying model is assumed based on pharmacological principles and understanding of drug properties. Such models are usually physiologically interpretable. Most machine learning (ML) approaches fall into culture 2, where no explicit model is specified, and a computer is responsible for identifying associations in the observed data. These models tend to be difficult to interpret physi-ologically, however, significant progress was made over the years in the interpretability of ML models.\\n6,7 T oday, many aspects of a black \\nbox model can be interpreted using proper tools.8\\nIn this paper, we aim to support readers to develop the intuition \\nneeded to understand how computers can learn or help humans to identify patterns in data. The foundational ideas of ML are high -', metadata={'source': 'introtoML.pdf', 'page': 0}),\n",
       " Document(page_content='In this paper, we aim to support readers to develop the intuition \\nneeded to understand how computers can learn or help humans to identify patterns in data. The foundational ideas of ML are high -\\nlighted, but we do not describe the details and theoretical back -\\nground of available ML methods. W e point the interested readers to other articles or books, such as “The Elements of Statistical Learning”\\n9 (referred as ESL), and we refer to examples of their ap -\\nplication in molecular biology, drug discovery, drug development, and clinical pharmacology.\\nW e first introduce the concepts of data points, features, feature \\nspaces, and similarity measures and then dive deeper into the two main domains of machine learning, namely unsupervised and su -\\npervised learning, touching key aspects and examples. In the case of unsupervised learning, computers are tasked to identify yet un -\\nknown patterns in data without pre-existing knowledge like groups or classes, whereas in the case of supervised learning, computers are tasked to learn how to predict the class or the value of yet unob -\\nserved data points based on a concept (often also called a “model”) that has been derived from a training dataset. Figure 1 shows a tax -\\nonomy of the different methods described in this paper and can be \\nReceived October 8, 2019; accepted January 15, 2020. doi:10.1002/cpt.17961Pharmaceutical Sciences, Roche Pharma Research and Early Development (pRED), Roche Innovation Center Basel, Basel, Switzerland. \\n*Correspondence: Solveig Badillo ( solveig.badillo@roche.com )\\n†S.B. was employed by Soladis Group during the time when the manuscript was written.Authors in alphabetical order. All authors contributed equally.[Correction added on 6th March, 2020, after first online publication: Author contribution text was added].\\nTUTORIAL', metadata={'source': 'introtoML.pdf', 'page': 0}),\n",
       " Document(page_content='VOLUME 107 NUMBER 4 | April 2020 | www.cpt-journal.com 872used as a reference, albeit nonexhaustive, on what scenario is suit -\\nable to apply which ML tool. Please note that all the unsupervised \\nmethods are also applicable in the case when labels are available.\\nDATA AND FEATURES\\nIn ML, we deal with data and datasets. A dataset is composed of multiple data points (sometimes also called samples), where each data point represents an entity we want to analyze. Therefore, a data point can represent anything like a patient or a sample taken from a cancer tissue. Many of the issues related to data are univer -\\nsal and affect not only ML approaches but any quantitative disci -\\npline, including pharmacometrics.\\nT o compile the dataset, one has measured and collected a \\nnumber of features (i.e., data that describe properties of the data Figure 1 Taxonomy and overview of main machine learning (ML) algorithms. ( a) Taxonomy of the different methods presented. ( b) Overview of \\nML methods. The spectrum of available methods ranges from simpler and more interpretable to more advanced algorithms with potentially \\nhigher performance at the expense of less interpretability. Position of methods on the figure is qualitative and in practice depends on the number of free parameters, model complexity, data type, and the exact definition of interpretability used.\\n8PCA, principal component analysis; \\nSVM, support vector machine; tSNE, t-distributed stochastic neighbor embedding; UMAP, uniform manifold approximation and projection.\\nA non-exhaus/g415ve guide  \\nto Machine Learning\\nUnsupervised learning Supervised learnin gUnlabelled dat a(a)\\n(b)Goal is to «explore»Labelled data\\nGoal is to «predict»\\nClusteringDimensionality \\nreduc/g415onRegression Classiﬁca/g415onFind subgroups Reduced dimensionalit y Numerical label Categorical label\\nK-means HierarchicalDensity-\\nbasedPCA tSNE UMAPK nearest  \\nneighbor sNaive \\nBayesDecision \\nTreesSVM \\nRegressio n\\nNeural \\nNetwork sRegressio nNeural \\nNetwork  \\nRegressio n\\nSVMytilibaterpretnILinear \\nregression\\nDecision  \\ntree s\\nK-Nearest \\nNeighbor sRandom  \\nforests\\nKernel \\nmethods\\nDeep Neural \\nNetwork s\\nPerformanc eBody  Size < 1.00m \\nKid Age > 18y YesNo\\nKid AdultYes No\\nFeatures Classifier Output label\\nInput \\nneuronshidden \\nneurons Output  \\nneuronssuppo rt \\nvectorsupport\\nvectors\\nop/g415mal  \\nhyperplanemargin\\nTUTORIAL\\n 15326535, 2020, 4, Downloaded from https://ascpt.onlinelibrary.wiley.com/doi/10.1002/cpt.1796, Wiley Online Library on [28/04/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License', metadata={'source': 'introtoML.pdf', 'page': 1}),\n",
       " Document(page_content='CLINICAL PHARMACOLOGY & THERAPEUTICS | VOLUME 107 NUMBER 4 | April 2020 873points). Those features can be categorical (predefined values of \\nno particular order like male and female), ordinal (predefined values that have an intrinsic order to them like a disease stage), or numerical (e.g., real values). For a patient in a clinical setting, these could be (combinations of ) the patient’s demographics, disease history, results of blood tests, or more complex and high dimensional measures, like gene expression profiles in a particu -\\nlar tissue or all single nucleotide polymorphisms that represent the patient’s unique genome.\\nEach feature represents one dimension of the feature space and \\nthe concrete value of a feature for a particular data point places the point in a defined place in this dimension of the space. T aken together, all the values of all features of a data point is called a feature vector. The more features we have collected for the data -\\nset, the higher the dimensionality of the resulting feature vector and the feature space. Obviously, as the dimensionality increases, visualization of all dimensions of the feature space becomes in -\\ntractable and we have to rely on the computer to identify the relevant patterns or have to apply dimensionality reduction methods, as explained later in the section “Dimensionality Reduction.”\\nClinical pharmacologists are usually familiar with longitudinal \\ndata, such as pharmacokinetic (PK) and pharmacodynamic (PD) profiles, where the time-dependency plays a central role. In fact, models used in pharmacometrics are based on equations that can be justified based on physiology and pharmacology, which yield insights into the time-evolution of the system. This is similar to, for example, physical problems, such as weather forecasts, where air flow and temperature lead to a certain temporal behavior of the system. In ML, including time as a distinguished continuous variable into respective algorithms, remains challenging and is an area of active research. As of now, several options exist to in -\\nclude time-dependent data in ML datasets: Either directly where each time point represents a feature, or via transformations, such as Fourier transform or B-splines, resulting in coefficients of basic functions that can be considered as features. Alternatively, Recurrent Neural Networks (RNNs) can be used to handle longitudinal data, as outlined in the section “Recurrent Neural Network.” However, all these approaches have the limitation of—directly or indirectly—discretizing the time-dimension.\\nMost ML algorithms are designed to handle high-dimensional \\ndatasets. Hence, derived features from the existing data are often included, such as log-transformed data, products, and ratios of fea -\\ntures, or more advanced combinations. Such data transformation is an important preprocessing step that can have a profound effect on the model performance. Therefore, it is always a good idea to use available domain knowledge and expertise to come up with relevant features, a process sometimes referred to as feature engineering.\\nData quality plays a crucial role in ML. Carefully chosen ML \\nmethods and visual inspection defend against extreme values or outliers. Missing data, however, can be challenging. Not all the methods support data missingness, and again data transformation could be required as a preprocessing step in such cases. There are various ways to impute missing data, the performance of which depends on the dataset and the method used.\\n10 The most triv -\\nial approach to the imputation is to replace a missing value with the feature mean across all the samples where it is defined. This, however, sometimes can cause overfitting\\n11 (also see the section \\n“Performance Measures and the Issue of Overfitting”).\\nIt is also essential to scrutinize any bias in the data (e.g., selec-', metadata={'source': 'introtoML.pdf', 'page': 2}),\n",
       " Document(page_content='11 (also see the section \\n“Performance Measures and the Issue of Overfitting”).\\nIt is also essential to scrutinize any bias in the data (e.g., selec-\\ntion bias). Preferably, samples for the ML should be an unbiased random subset of the population. In practice, this is rarely the case, and there are some biases in the data. These biases can af-fect the ability of the model to generalize beyond the training dataset (and even the test dataset if both share a similar bias). An example of such a generalization problem is a model that is supposed to learn how to distinguish a wolf from a husky by animal characteristics, but eventually turns out to simply iden -\\ntify patches of snow on the photograph.\\n6 There are various \\napproaches to mitigate bias (e.g., one could down-weight or completely exclude biased samples or features).\\n12 In particu -\\nlar, propensity scores are useful when estimating the effect of a therapeutic intervention.\\n13 Inspection of the feature importance \\nprovides valuable information about the magnitude and the ef-fect of the bias,\\n6,7 which is recommend to be used for checking \\nthe trustworthiness of ML models.\\nMany clinical classification datasets are unbalanced, meaning that \\none or more classes are underrepresented. This could pose difficulties for many ML algorithms, including artificial neural networks and gradient boosting methods. One way to mitigate this problem is un -\\ndersampling/oversampling the majority/minority class, respectively, or tweaking the misclassification cost in the objective function.\\n14\\nFinally, for many applications, it is important to define a simi-\\nlarity or distance measure between two data points in the feature space. The simplest distance measure would be the Euclidean distance:\\nbetween the numerical feature vectors of two data points A and \\nB, for features \\ni=1…n, but depending on the type of data we are \\ndealing with there can be many other and sometimes much more complex distance or similarity measures, such as cosine similarity\\n15 \\nor similarity scores of two biological sequences.16\\nMain takeaways\\n• Transforming input data and feature engineering may improve the model.\\n• Missing data requires imputation.\\n• Biases in the data should be scrutinized.\\n• Unbalanced datasets require amendment of the model.\\n• Meaningful measures of similarity between the samples should be defined.\\nUNSUPERVISED LEARNING\\nIn exploratory data analysis, we often do not know the true “labels,” or we might want to examine the naturally emerging patterns in the data. For this purpose, we can use unsupervised learning methods, like clustering, frequent pattern detection, and dimensionality reduction. Here, we will focus particularly (1)d(A,B)=/uni221A.t/uni221A.x/uni221A.x/uni221A.s4n/uni2211.s1\\ni=1(ai−bi)2\\nTUTORIAL\\n 15326535, 2020, 4, Downloaded from https://ascpt.onlinelibrary.wiley.com/doi/10.1002/cpt.1796, Wiley Online Library on [28/04/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License', metadata={'source': 'introtoML.pdf', 'page': 2}),\n",
       " Document(page_content='VOLUME 107 NUMBER 4 | April 2020 | www.cpt-journal.com 874on clustering and dimensionality reduction as they have many \\napplications in molecular biology and clinical practice.\\nClustering\\nThe goal of applying clustering methods is to identify relevant sub -\\ngroups in a given dataset without having a predefined hypothesis on the properties subgroups might have. For example, in a cohort of patients with a particular disease, we might want to identify subtypes that represent distinct biological mechanisms driving the disease based on molecular measures taken.\\n17\\nA cluster is a subset of the data which are “similar” to each other, \\nwhereas points belonging to different clusters are more “different.” There are multiple approaches to clustering that use different un -\\nderlying algorithms to group data points by their “similarity.” All of them have advantages and disadvantages and needed to be selected carefully depending on the application and properties of the data.\\nOne simple approach to clustering is k-means clustering.\\n18 Here, \\nthe number of clusters to be identified is predefined by a user-se -\\nlected parameter k. Each cluster is represented by a cluster center, which is an artificial data point that represents the mean (or me -\\ndian) value of all points assigned to this cluster. In the beginning, k \\ncluster centers, known as “seeds, ” are randomly placed in the feature space. The algorithm then iterates through two steps. In step one (“assignment”), data points are assigned to the cluster represented by the closest center. In step two (“center shift”), the position of each cluster center is updated based on the composition of the clus-ters after step one. After a number of iterations, this will usually converge to a local optimum where cluster assignments do not or only marginally change. The result of such a process is visualized in Figure 2b. Although the procedure is intuitive, its major drawback \\nis that usually the clustering is strongly influenced by the value of k, and more often than not the true number of clusters in the data is unknown a priori. Because there is rarely a clear cut right or wrong \\nanswer in clustering, further cluster investigation is required to identify meaningful clusters, which can be challenging particularly in the light of a high-dimensional feature space.\\nAnother group of methods for clustering is density-based cluster -\\ning.\\n19 In density-based methods, a cluster represents a part of the fea -\\nture space where data points are dense. Data points belonging to the regions of the feature space with low density are considered to be noise. One of the well-known density-based clustering algorithms is Density-Based Spatial Clustering of Applications with Noise.\\n20 Density-based \\nclustering does not require a predefined value setting the number of clusters and provides a reproducible result. Further, it is able to also identify complex cluster shapes, like the one shown in Figure 2c.\\nIn hierarchical clustering analysis, the goal is to build a hierarchy \\nof clusters (ESL, chapter 14).\\n9 One simple approach to hierarchical \\nclustering is neighbor joining. First, all pairwise distances between all data points in the dataset are computed. Later, in every step of an iterative process, the two data points with smallest distance are grouped together. This results in a tree-like cluster structure, as dis-played in Figure 2a on the left side and top of the heatmap where \\nthe branch lengths of the tree represent the distances of samples. T o arrive at a discrete set of clusters like with k -means a distance thresh -\\nold has to be chosen at which the tree is cut horizontally. Again, there is no optimal way of selecting such a threshold and many reasonable solutions may exist. Hierarchical clustering can be used alone, or used in combinations with heatmaps (e.g., Figure 2a) to \\nvisualize selected or all features, for instance, gene expression data.\\nDimensionality reduction', metadata={'source': 'introtoML.pdf', 'page': 3}),\n",
       " Document(page_content='visualize selected or all features, for instance, gene expression data.\\nDimensionality reduction\\nThe number of features and, therefore, the dimensionality of the feature space can be very high with tens of thousands of measures per sample. Not only does this make data visualization challenging but also the analysis is challenging. In particular, analysis of high-di -\\nmensional datasets can be associated with a phenomenon known as the “curse of dimensionality,”\\n21 which refers to data sparsity \\nand counterintuitive geometrical properties in high-dimensional \\nFigure 2 Overview of the results of different clustering approaches. ( a) Shows the results of a two-dimensional hierarchical clustering. The two \\ndendrograms visualize the similarity across samples and also across the markers measured. Such visualization is frequently used in biology \\nfor gene expression or other -omics technology readouts. ( b) Shows the outcome of a classical clustering using k -means with a selected value \\nof k\\xa0=\\xa02. Resulting clusters are usually convex and every point is assigned to one cluster, namely the one which is represented by the closest center point (marked by X). ( c) Shows the result of a density-based clustering. Please note that the approach can identify nonconvex cluster \\nforms, such as the orange cluster.Subject_2Subject_8Subject_10Subject_4Subject_6Subject_1Subject_7Subject_9Subject_3Subject_5Mark er_19\\nMark er_18\\nMark er_16\\nMark er_17\\nMark er_15\\nMark er_20\\nMark er_5\\nMark er_3\\nMark er_7\\nMark er_4\\nMark er_1\\nMark er_9\\nMark er_6\\nMark er_10\\nMark er_2\\nMark er_8\\nMark er_13\\nMark er_12\\nMark er_11\\nMark er_14−202468(a) (b) (c)\\nTUTORIAL\\n 15326535, 2020, 4, Downloaded from https://ascpt.onlinelibrary.wiley.com/doi/10.1002/cpt.1796, Wiley Online Library on [28/04/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License', metadata={'source': 'introtoML.pdf', 'page': 3}),\n",
       " Document(page_content='CLINICAL PHARMACOLOGY & THERAPEUTICS | VOLUME 107 NUMBER 4 | April 2020 875spaces. The “curse of dimensionality” poses challenges on most \\ndata analysis approaches, including but not limited to ML.\\nT o mitigate such problems dimensionality reduction methods \\nmight be applied. Dimensionality reduction can aid data visualization by transforming each high-dimensional data point into two or more di-mensions while keeping the majority of the variability and relative dis-tances. Furthermore, dropping uninformative features could improve the model performance and convergence time. Although some of these methods, like principal component analysis, have even been de -\\nveloped long before the term ML has been coined,\\n22 others, like t-Dis-\\ntributed Stochastic Neighbor Embedding23 or Uniform Manifold \\nApproximation and Projection,24 were developed recently and address \\ncomplex challenges arising in data analysis. There is also a powerful neural network-based dimensionality reduction approach called au -\\ntoencoder. For details on how to apply dimensionality reduction in biomedical data, we would like to refer the reader to a recent review.\\n25\\nExamples of unsupervised ML applications\\nClustering is widely used when analyzing high-dimensional data, such as transcriptomic, metabolomic, and proteomic ex -\\nperiments. Typically, hierarchical clustering would be used to identify main factors affecting the readouts as well as for identifi -\\ncation of modules with high degree of coregulation. In single-cell sequencing, nonhierarchical clustering is used to understand which cell types are present in the sample. Clustering is also used to identify relationships among patients, tissues, diseases, or even disease symptoms.\\n26–29 Drug compounds themselves may also be \\nclustered based on gene expression, sensitivity, and target protein properties\\n30–32 with the goal of guiding drug discovery.\\nDimensionality reduction is routinely used in transcriptomic \\nand other -omics experiments, usually to identify outliers and po -\\ntential batch effects. In single-cell sequencing, Uniform Manifold Approximation and Projection or t-Distributed Stochastic Neighbor Embedding are used both for data visualization and for subsequent clustering.\\n24 Dimensionality reduction is also used to \\nvisualize the high-dimensional chemical space33 or as a prepro -\\ncessing step to improve performance of an ML model.34\\nMain takeaways\\n• Clustering can be used to understand structure in data by grouping similar observations together.\\n• k-means clustering is a simple yet powerful tool, however, the \\nnumber of clusters must be specified in advance.\\n• Density-based methods do not require a prespecified number of clusters and allows identification of complex patterns in the data.\\n• Hierarchical clustering provides an overview of the relationship on multiple levels.\\n• Dimensionality reduction is used not only for data visualization but also to drop uninformative features.\\nSUPERVISED LEARNING\\nIn a supervised learning problem, the computer is fed training data with observations and the corresponding known output val -\\nues. The goal is to learn general rules (also often called a “model”) that map inputs to outputs, so that it will be possible to predict the output for new unseen data, where we have observed input values but not their associated output.\\nThere are two main categories of supervised learning: (i) classi-\\nfication where the output values are categorical, and (ii) regression where the output values are numeric.\\nIn subsequent sections, the context of model fitting in supervised \\nlearning and the common issue of overfitting are introduced. Then, we explain how the performance is evaluated for classification and regression tools (i.e., how to assess the quality of mapping from in -', metadata={'source': 'introtoML.pdf', 'page': 4}),\n",
       " Document(page_content='puts to outputs by the algorithm). This aspect is essential, as the merit of adopting ML methods often centers around the prospect of obtaining higher performance with the trade-off of interpretability. Understanding the different performance metrics enables better eval -\\nuation of the merits of a proposed model, as opposed to an assumption that an ML solution could always outperform a traditional approach.\\nW e then dive into some of the existing classification and regres-\\nsion methods, starting off at the shallow end, where interpretation of the models is still straightforward, and progressing toward more ML-centric approaches where performance triumphs, often at the expense of interpretability. Figure 1 summarizes the available spec-\\ntrum of methods with respect to performance and interpretability. This section concludes with a nonexhaustive review of the applica -\\ntions of supervised learning methods in biology and, particularly, clinical pharmacology.\\nPerformance measures and the issue of overfitting\\nThe goal of a learning algorithm is to learn a concept or function (= a model) that describes the observed training data and is able to generalize on new independent data by avoiding both underfitting and overfitting.\\nThe performance of a model is evaluated by methods that allow \\nmodel assessment (i.e., estimating how well a given model performs in general and model selection; and the estimation of the perfor -\\nmance of different models to choose the most adequate model). Some of these methods are highlighted in the next sections.\\nModel fitting.  The model parameters are estimated based \\non observed data in the training set. To derive the optimal parameter values (e.g., for coefficients and weights), a distance measure between model and data is defined and minimized numerically. Independently of the metric chosen, the goal of model fitting is always to estimate the parameters by minimizing the distance, also called loss function  or cost function , with two \\nrequirements:\\n• The model should provide predicted values that are close to ob -\\nserved ones on the training set, otherwise we say that it under -\\nfits and has a high bias .\\n• The model should generalize beyond the training set. A model \\nthat overfits  predicts well on the training set but poorly on an \\nindependent test set, often because it is too complex for the data. In this case, we also talk about high variance .\\nIn the following, we will call objective function any function that \\nis optimized to estimate the model parameters.\\nTUTORIAL\\n 15326535, 2020, 4, Downloaded from https://ascpt.onlinelibrary.wiley.com/doi/10.1002/cpt.1796, Wiley Online Library on [28/04/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License', metadata={'source': 'introtoML.pdf', 'page': 4}),\n",
       " Document(page_content='VOLUME 107 NUMBER 4 | April 2020 | www.cpt-journal.com 876In the regression case, Figure 3 illustrates the issue of underfitting \\nand overfitting in the context of regression. Underfitting can occur \\nwhen the model is too simple or when the features extracted from the data are not informative enough (Figure 3, left panel). Overfitting \\noften occurs when the model is too complex or there are too many features over a small set of training examples (Figure 3, right panel).\\nThis underfitting/overfitting issue is also often referred to as the \\nbias/variance trade-off, which comes from the expression of the ex -\\npected prediction error, including both bias and variance terms. The bias is an indication of the average error of the model for different training sets: It is the discrepancy between average of predicted val -\\nues and the true mean we are trying to predict. The variance reflects the sensitivity of the model to the training set: For a given point, it corresponds to the spread of predicted values around their mean.\\nT o minimize the predicted error, there is a trade-off between \\nminimizing bias and variance: Increasing model complexity de -\\ncreases bias but increases variance. T o build less complex models, different techniques exist summarized under the term regulariza -\\ntion. The principle consists in modifying the objective function by adding penalization terms that will influence parameter estimation. L1 and L2 regularization are the most common ones (ESL, sections 3.4.1 and 3.4.2).\\n9\\nDifferent categories of loss functions.  Different objective \\nfunctions can be chosen to measure the distance between observed data and values predicted by the model. Some of the distance metrics used in practice can be associated to a likelihood . \\nThe likelihood indicates how probable it is to observe our data according to the selected model. The most common use of a likelihood is to find the parameters that make the model fit optimally to the data (i.e., the maximum likelihood parameter estimates). Usually, the negative logarithm of the likelihood is minimized and considered as objective function because it has favorable numerical properties. Similarly, in ML metrics, such as mean squared error, logistic objective, or cross-entropy, are used to find optimal parameters or assess the fitness of the model.\\nIn practice, analytical calculation of maximum likelihood or \\nminimal loss may not be feasible, and it is often necessary to use a numerical optimization algorithm to solve for the best parameter values. Gradient descent is such an algorithm, where we first define \\nan objective function for which we want to minimize and then  iteratively  update the values of the parameters in the direction with \\nthe steepest decrease (first-order derivative) of the objective func-\\ntion until a convergence to a minimum distance is deemed reached. In the scenario of a nonconvex objective function, the success of finding a global minimum, as opposed to landing in some local minima, will depend on the choice of the initial set of parameter values, the learning rate (i.e., step size of each iteration) and the cri-terion for convergence. The reader can refer to ref. \\n35 for details on \\nconvex and nonconvex optimization processes. Stochastic gradient descent is an additional trick that can further speed up the optimi-zation by randomly sampling a training dataset and summing the distances across this subset of training data points for approximat -\\ning the objective function.\\nGeneral principle of model selection and assessment.  The problem \\nof overfitting shows that the model performance on the training set is not a good indicator of its performance on a new dataset. We will detail below the principles of model performance evaluation in a supervised learning setting.\\nThe general principle of model selection is as follows: When there \\nare enough data, we separate them into three subsets—training,', metadata={'source': 'introtoML.pdf', 'page': 5}),\n",
       " Document(page_content='The general principle of model selection is as follows: When there \\nare enough data, we separate them into three subsets—training,  \\nvalidation, and test sets. The training set is used to build different models, whereas the validation set is subsequently used to choose the algorithm and select the hyperparameters, if needed. Then, the model with the best performance on the validation set is selected. Finally, the test set enables to assess the generalization error, also called test error , which is the prediction error over a test dataset Figure 3 Illustration of the underfitting/overfitting issue on a simple regression case. Data points are shown as blue dots and model fits \\nas red lines. Underfitting occurs with a linear model (left panel), a good fit with a polynomial of degree 4 (center panel), and overfitting with \\npolynomial of degree 20 (right panel). Root mean squared error is chosen as objective function for evaluating the training error and the generalization error, assessed by using 10-fold cross-validation.GG\\nGG\\nGGG\\nG\\nG\\nGGG\\nG\\nGG\\nG\\nGGGGGG\\nGG\\nGG\\nG\\nGGG\\n19.019.520.020.521.0\\n0.00 0.25 0.50 0.75 1.00\\nX\\nUnderfityTraining erro r: 0.4\\nGeneralization erro r: 0.42Polynomial fit degree 1\\nGG\\nGG\\nGGG\\nG\\nG\\nGGG\\nG\\nGG\\nG\\nGG\\nGGGG\\nGG\\nGG\\nG\\nGGG\\n19.019.520.020.521.0\\n0.00 0.25 0.50 0.75 1.00\\nX\\nGood fitTraining erro r: 0.14\\nGeneralization erro r: 0.17Polynomial fit degree 4\\nGG\\nGG\\nGGG\\nG\\nG\\nGGG\\nG\\nGG\\nG\\nGG\\nGGGG\\nGG\\nGG\\nG\\nGGG\\n19.019.520.020.521.0\\n0.00 0.25 0.50 0.75 1.00\\nX\\nOverfitTraining erro r: 0.07\\nGeneralization erro r: 2000Polynomial fit degree 20\\nTUTORIAL\\n 15326535, 2020, 4, Downloaded from https://ascpt.onlinelibrary.wiley.com/doi/10.1002/cpt.1796, Wiley Online Library on [28/04/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License', metadata={'source': 'introtoML.pdf', 'page': 5}),\n",
       " Document(page_content='CLINICAL PHARMACOLOGY & THERAPEUTICS | VOLUME 107 NUMBER 4 | April 2020 877that was not used during the training.9 It is important to note here \\nthat the generalization error could be higher than expected when \\nthe original dataset is biased (see the section “Data and features”). V alidating the model against a fully independent test dataset is the gold-standard method of assessing the generalizability of the model.\\nWhen the dataset is too small to extract a decent validation \\nset, it is, for example, possible to use cross-validation techniques to select model hyperparameters. After putting aside a subset of the data for testing, k -fold validation consists of dividing the \\ntraining set into k  subsets, \\nk−1 subsets being used for train -\\ning and the last one to assess the performance. This process is repeated k times, each k  subset being used once for validation, \\nand the performance scores from each subset are then averaged for each set of hyperparameters to test. The k -fold cross-valida -\\ntion procedure is summarized in Figure 4. T o choose between \\ndifferent learning algorithms\\n36 nested cross-validation can be \\nused.\\nIndicators of model complexity vs. goodness of fit . In \\npharmacometrics, model selection is usually based on quantitative measures that summarize how well the model fits the data, often with penalties for overfitting. The most commonly used are the Akaike information criterion and Bayesian information criterion. They penalize the number of model parameters and reward goodness of fit, measured through likelihood. The Akaike information criterion is formalized as:\\nwith the number of parameters M  and the maximum likelihood \\n̂\\ue238.In contrast, the Bayesian information criterion:\\ntakes into account the number of data points n .\\nThese model selection approaches are rarely used in ML, partly \\ndue to the complexity of datasets and the associated violation of \\ndistributional assumptions. Instead, approaches like cross-valida -\\ntion are more commonly used (Clustering).\\nPerformance measures for model assessment.  For regression \\nmodels, we typically use the mean squared error, or other types of average objective functions, to compare model performance on training and test set. For two-class classification problems, common performances measures are often derived from the “confusion matrix” shown in Figure 5 and briefly described below.\\n• Precision, corresponding to the ratio of correctly predicted pos -\\nitive values to the total number of predicted positive values.\\n• Recall, also called true positive rate (TPR) corresponding to the ratio of correctly predicted positive values to the total number of positive values in the dataset.\\n• False Positive Rate (FPR), corresponds to the proportion of negative values predicted incorrectly.\\n• Accuracy, corresponding to the number of correctly predicted values divided by the total number of predicted values.\\n• Area under the ROC curve (AUC): Receiver operating charac -\\nteristic (ROC ) curves show the TPR (recall) and FPR depen -\\ndence. In binary classification, each point on the ROC curve is located by choosing different thresholds for classification of \\nyi in \\npositive or negative class. The top left corner of an ROC curve (2) AIC=2M−2 ln ( ̂\\ue238),(3) BIC=ln (n) ⋅M−2 ln ( ̂\\ue238),\\nFigure 4 Illustration of the general principles of supervised learning in the case of a limited dataset. To assess the generalization ability of \\na supervised learning algorithm, data are separated into a training subset used for building the model and a test subset used to assess he \\ngeneralization error.Limited dataset\\n1 subset k-1 subsetsTraining folds Test  fold\\n.\\n..Score 1\\nS1\\nScore 2\\nS1\\nScore k\\nSk\\nFore achr un:\\n•model built on k-1 subsets\\n•performancem easure computed on \\ntest subset formodel valida/g415o nrun 1\\nrun 2\\nrun kTraining subset Test \\nsubset       \\nFinal model\\nbuilt on training\\nsubset Evaluate model on test set(generaliza/g415on error)Fore achmodel t otest\\nAverage  \\nofscores\\nover the\\nk runs', metadata={'source': 'introtoML.pdf', 'page': 6}),\n",
       " Document(page_content='run 2\\nrun kTraining subset Test \\nsubset       \\nFinal model\\nbuilt on training\\nsubset Evaluate model on test set(generaliza/g415on error)Fore achmodel t otest\\nAverage  \\nofscores\\nover the\\nk runs\\nSelect model with best metric\\nTUTORIAL\\n 15326535, 2020, 4, Downloaded from https://ascpt.onlinelibrary.wiley.com/doi/10.1002/cpt.1796, Wiley Online Library on [28/04/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License', metadata={'source': 'introtoML.pdf', 'page': 6}),\n",
       " Document(page_content='VOLUME 107 NUMBER 4 | April 2020 | www.cpt-journal.com 878is the ideal case with 100% of positive values correctly classified \\n(TPR\\xa0=\\xa01) and 0% of positive values incorrectly predicted at 0 (FPR\\xa0=\\xa00). As it is ideal to maximize the TPR while minimizing the FPR, a larger area under the ROC curve (AUC) is better.\\nSome of these metrics could be generalized for multiclass \\nproblems, where there are more than two different labels in the \\ndataset. However, the metrics mentioned above are noncon -\\ntinuous with respect to model parameters, hence, parameter optimization may be challenging when they are used as objec-tive function. A continuous alternative and widely used metric previously mentioned in the section “Model fitting” is cross-en -\\ntropy (ESL, chapter 9),\\n9 which not only accounts for the most \\nlikely prediction but also for the prediction score (prediction confidence).\\nk-Nearest neighbors \\nWe start our overview on existing learning methods with a method that skips the learning step completely and, therefore, does not lead to an explicit model that is being learned from the training data. As we will discuss later, this is also one of its biggest shortcomings. This type of learning is also often referred to as “instance-based learning” and, in our particular example, “ k-nearest neighbor learning\" (kNN).\\n37\\nIn these approaches, learning simply consists of storing all the \\nexisting, labeled data points (i.e., the training data) in a database. When a new, yet unclassified example is observed, the algorithm will place it in the n -dimensional feature space based on its feature values. \\nFor each data point in the database, we now compute the distance (e.g., a Euclidean distance or other, more complex ones) to this new data point in order to identify its k  closest neighbors. In a second \\nstep, we examine the known labels of these k NNs in our database. \\nSay we have chosen k  to be nine and we observe seven of the nearest \\nneighbors to be labeled as class X whereas two of them are labeled as class Y. In this case, we would assign our new data point to the class X as the majority of its neighbors are of this class. An exten -\\nsion of this simple approach would be to weight the importance of the neighbors to the classification by their distance to the new data point. Despite being very straightforward and simple, it proves to be a very effective classification method in practice. It is very efficient when it comes to training (i.e., storing the data in the database) and efficient implementations for computing the k NNs exist.\\nSo, what are the challenges to this approach? The most obvious \\none is that because there is no “learning step, ” the k NNs approach \\ndoes not identify the features that are really relevant to predict the class of a new case. Therefore, even though in a 20-dimensional fea -\\nture space, where only 2 might be really relevant for the classification, the distance will be computed taking all 20 dimensions into account. Thus, the k  nearest data points returned by the query will be highly \\ninfluenced by irrelevant features or noise (see also “Dimensionality reduction” on how to remove some of those features). As a conse -\\nquence, the resulting classification will be driven by noise rather than the real underlying pattern in the data. In this aspect, the approach suffers from the same challenge that also clustering approaches (see the section “Clustering”) are facing, which are often summarized as the “curse of dimensionality.”\\n21\\nNaive Bayes\\nThe second and very intuitive learning approach we would like to introduce is naive Bayes. It is based on computing simple sta -\\ntistics from a given training dataset as the learning step following a straightforward (but naive) application of the Bayesian formula for conditional probability in order to obtain a classification. Due to its simplicity it is also often used to obtain a baseline clas -', metadata={'source': 'introtoML.pdf', 'page': 7}),\n",
       " Document(page_content='sification performance that other, more involved methods have to improve upon. It can best be explained by a simple example.\\nLet us assume we have training dataset with patients suffering either \\nfrom a harmless cold or an influenza (flu) infection. W e have measured two features for each patient, namely fever (high, low, or no) and pain (strong, low, or no). For each patient, we know through a laboratory test if the patient had an influenza infection or not. W e now want to learn from these data and apply it to diagnose a new patient (where we have no laboratory test available) using the naive Bayes approach.\\nAs a learning step, we count for each feature value how often it oc-\\ncurs in the influenza and in the cold patient group (e.g., to obtain the probability for high fever under the condition of the patient having a flu and so on). The result of this learning step might be seen in T able 1.Figure 5 Confusion matrix for two-class problems. The confusion matrix indicates how successful the algorithm was at predicting labels in \\na binary classification problem where labels take values 0 (called “negative”) or 1 (called “positive”) by evaluating the predicted vs. the real \\nlabels. Every data point in the test set belongs to one of the four categories and different measures can be derived from these numbers.10\\n1 True P osi/g415 ve (TP) False Ne ga/g415ve (FN)Recall=TPR  \\n(True Posi/g415ve Rate )\\nTPR = +\\n0 False Posi/g415ve (FP) True Neg a/g415ve (TN )Speciﬁcity =+\\nFalse Posi/g415ve Rate: \\nFPR = +\\nPrecisio n\\n+False Neg a/g415ve Rate\\n+Accu racy\\n+\\n+++Predicted labels\\nActual label s\\n(observ a/g415ons)\\nTUTORIAL\\n 15326535, 2020, 4, Downloaded from https://ascpt.onlinelibrary.wiley.com/doi/10.1002/cpt.1796, Wiley Online Library on [28/04/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License', metadata={'source': 'introtoML.pdf', 'page': 7}),\n",
       " Document(page_content='CLINICAL PHARMACOLOGY & THERAPEUTICS | VOLUME 107 NUMBER 4 | April 2020 879T able 1 summarizes probability of each feature given the cat -\\negory of patient and shows that in the whole patient population \\nthe probability for a patient having an influenza infection is 0.1, whereas the probability for a normal cold is 0.9.\\nOnce we have generated these values and, therefore, completed \\nthe “learning step” by analyzing our dataset, naive Bayes makes a now naive assumption, which is that all these features are conditionally independent of one another. In reality, this is rarely true and there are more advanced Bayesian learning methods that do not make this assumption. However, the assumption allows for a straightforward application of the Bayesian theorem. For details (i.e., formulas) on how to derive this classifier, we would like to refer the reader to fur -\\nther reading material (ESL, chapter 6).\\n9 In brief, the probability of \\na certain label (flu or cold) for a new test item can be computed as the product of the single conditional feature probabilities (fever and pain) that are observed for the data point times the probability for the class (flu or cold). The class with the maximal posterior likeli-hood is selected as the predicted class for the test item. Assuming we have a test person with an unknown diagnosis for influenza or cold, and we know that this person shows up with high fever and a high level of pain, we would compute the likelihood for influenza as:\\nIn the same way we would compute the likelihood for a cold as:\\nFor a patient that presents to the doctor with high fever and \\nstrong muscular pain or headache, this results in a (nonnormal -\\nized) posterior probability for an influenza infection of 7.125% \\nand in a probability of 2.7% for a normal cold. Therefore, the pa -\\ntient suffers more likely from a flu than from a cold.\\nIn many aspects, naive Bayes, therefore, formalizes how humans \\nmight learn from experience.\\nDecision trees, random forests, and gradient boosting\\nDecision trees are an essential building block for many ML al -\\ngorithms. They have been used for at least 50 years.38,39 The \\nidea behind decision trees is very intuitive and best represented in a visual form (e.g., Figure 1). Depending on the problem, de -\\ncision tree leaf nodes have classes, probabilities, or continuous values in case of regression. In the early days of ML, decision trees have been used to solve pharmacological problems, such as dosing, toxicology, and diagnostics.\\n40–42 Although usage of \\ndecision trees is intuitive, the question is how to construct such trees from the available data. A few famous approaches worth mentioning are CART\\n43 and ID3.44\\nCurrently, decision trees are almost never used in ML in their \\noriginal form. One of the reasons being is the fact that decision trees are prone to overfitting. Nevertheless, decision trees became the building block for two widely used approaches: Random deci-sion forests and gradient boosting frameworks.\\nBoth random decision forests and tree-based gradient boosting \\nuse a set (ensemble) of trained decision trees to predict the out -\\ncome variable. The crucial difference between tree-based gradient boosting and random decision forests is on how trees are created.\\nIn case of random forests, the algorithm constructs hundreds \\nor thousands of deep decision trees (“strong predictors”). Each of those trees is likely overfitted, however, by combining the outputs of multiple trees we can solve the overtraining problem. On the contrary, in a gradient boosting algorithm, such as XGBoost or CatBoost, each of the trees is a shallow decision tree (“weak predic-tor”), and the algorithm iteratively decreases the classification error over time by adding more and more trees.\\nT oday, gradient boosting methods show a great performance \\nboth in publications and ML competitions. Even without hyper -\\nparameter tuning, they usually provide excellent performance with a relatively low computational cost.', metadata={'source': 'introtoML.pdf', 'page': 8}),\n",
       " Document(page_content='both in publications and ML competitions. Even without hyper -\\nparameter tuning, they usually provide excellent performance with a relatively low computational cost.\\n11 On the other hand, \\nrandom forests are usually less prone to overfitting45 and re -\\nquire less parameter tuning.46 This makes random decision for -\\nests attractive for smaller datasets or as a baseline method for benchmarking.\\nT ree ensemble methods can be used for classification tasks, as \\nwell as for regression. In both cases, tree outputs are averaged, which can create a smooth output function.\\nKernel methods: Support vector machines and regression\\nKernel methods and, more specifically, support vector machine (SVM) for classification and support vector regression (SVR) for continuous output have found applications in computational biol -\\nogy for their ability to be robust against noise and to work with high-dimensional datasets found in genetics, transcriptomics, and proteomics.\\n47 Concretely in a more recent example, SVR was used \\nfor delineating cell compositions from bulk transcriptomics data.48(4)P(Fever=High /uni007C.varFlu) ⋅P(Pain=Strong /uni007C.varFlu)⋅\\nP(Flu) =0.95 ⋅0.75 ⋅0.1=0.07125.\\n(5)P(Fever=High /uni007C.varCold) ⋅P(Pain=Strong/uni007C.varCold)⋅\\nP(Cold) =0.1 ⋅0.3 ⋅0.9=0.027.Table 1 Illustration of naive Bayes: Example of learning step results on flu dataset, showing the probabilities of features \\nvalues given the patient category\\nFeatures Fever Pain\\nClasses High Low No Strong Low No\\nInfluenza (Flu)\\nP (Flu)\\xa0=\\xa00.1 P(Fever\\xa0=\\xa0High|Flu) \\n\\xa0=\\xa00.95P(Fever\\xa0=\\xa0Low|Flu) \\n\\xa0=\\xa00.05P(Fever\\xa0=\\xa0No|Flu) \\n\\xa0=\\xa00P(Pain\\xa0=\\xa0Strong|Flu) \\n\\xa0=\\xa00.75P(Pain\\xa0=\\xa0Low|Flu) \\n\\xa0=\\xa00.20P(Pain\\xa0=\\xa0No|Flu) \\n\\xa0=\\xa00.05\\nCold\\nP(Cold)\\xa0=\\xa00.9 P(Fever\\xa0=\\xa0High|Cold) \\n\\xa0=\\xa00.1P(Fever\\xa0=\\xa0Low|Cold) \\n\\xa0=\\xa00.4P(Fever\\xa0=\\xa0No|Cold) \\n\\xa0=\\xa00.5P(Pain\\xa0=\\xa0Strong|Cold) \\n\\xa0=\\xa00.3P(Pain\\xa0=\\xa0Low|Cold) \\n\\xa0=\\xa00.3P(Pain\\xa0=\\xa0No|Cold) \\n\\xa0=\\xa00.4\\nTUTORIAL\\n 15326535, 2020, 4, Downloaded from https://ascpt.onlinelibrary.wiley.com/doi/10.1002/cpt.1796, Wiley Online Library on [28/04/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License', metadata={'source': 'introtoML.pdf', 'page': 8}),\n",
       " Document(page_content='VOLUME 107 NUMBER 4 | April 2020 | www.cpt-journal.com 880This section first offers a brief overview of the key concepts \\nhighlighting the notions of kernel transformations, an objective \\nfunction with a lossless region, and a regularization term.49,50 The \\nemphasis will be placed on providing the reasoning behind why this is a more versatile method in dealing with multiple inputs where their effects on the output are unknown and can be postu -\\nlated to span into nonlinear functions.\\nBackground.  Similar to all regression methods, the objective \\nof SVR is to postulate a function on the input(s) that can help estimate for the observed output. Likewise, for SVM, the goal is to find the optimal decision boundary that separates the classes. As the name suggests, the core concept behind SVM/regression is the ability to objectively choose a subset of training data called support vectors. These support vectors define the model, which is usually a hyperplane in some feature space. To achieve this, several notions need to be introduced.\\n• An \\nε-insensitive loss  function allows for residual less than ε, to \\nbe considered lossless and, thus, not part of the support vectors \\nfactored in to estimate the output-input function.\\n• A regularization term  is added to the objective function with \\nthe aim of searching for a model to describe the relationship be -\\ntween the input and output variables such that the hyperplane is kept as flat as possible.\\n• Slack variables can be introduced to allow for training errors, termed soft margin, when the output is found outside the \\nε-in-\\nsensitive region. By introducing slack variables, tolerance for the residual term to be greater than \\nε is made.\\n• A kernel function  allows us to work in a higher dimension space, feature space. A kernel function applied in the input space cor -\\nresponds to a dot product in the feature space where similarity measures are computed. This is achieved without having to ex -\\nplicitly map the input data from the input space to some feature space by some mapping function \\nϕ.\\nWith all these concepts at hand, we are now capable of fitting a \\nmodel with some thickness, known as a tube introduced by the ε-in-\\nsensitive loss function, whereas the regularization term controls for the flatness of this hyperplane in some feature space defined by the kernel function. Figure 6 illustrates these basic concepts of SVM.\\nKernel trick and choice.  SVR can capture nonlinear target \\nfunctions, which map the multivariate inputs to the output. More precisely, the kernel trick means that a kernel:\\napplied to a set of inputs in the input space is equivalent to comput -\\ning the dot product as a similarity measure in some feature space. \\nThis is achieved without having to explicitly perform a pre-map -\\nping of the inputs, \\nxi, with a mapping function Φ. A kernel func -\\ntion calculated in the input space corresponds to a dot product in some feature space if and only if it is a symmetric positive definite function.\\n51,52\\nThe choice of the radial basis function kernel,\\nis often made as it can be expanded to a feature space of infinite dimensions. Although radial basis function covers a wide range (6)k(xi,xj):=⟨Φ(xi),Φ(xj)⟩\\n(7) ⟨Φ(xi),Φ(xj)⟩:=k(xi,xj)RBF=exp−γ(∥xi−xj∥)2\\nFigure 6 Illustration of support vector machine (SVM) principles. ( a) Illustration of a simple case where hyperplane separate two groups \\ndirectly in inputs space. ( b) Illustration of performing nonlinear classification by implicitly mapping inputs into high-dimensional feature spaces \\nwhere data points can be separated by a hyperplane.Input space\\nFeature spaceConstruc onof hyperplane\\nimplicit mapping \\nby kernel tric k\\n(b)(a)\\nopmal\\nhyperplanemarginsupport \\nvectors\\nTUTORIAL', metadata={'source': 'introtoML.pdf', 'page': 9}),\n",
       " Document(page_content='where data points can be separated by a hyperplane.Input space\\nFeature spaceConstruc onof hyperplane\\nimplicit mapping \\nby kernel tric k\\n(b)(a)\\nopmal\\nhyperplanemarginsupport \\nvectors\\nTUTORIAL\\n 15326535, 2020, 4, Downloaded from https://ascpt.onlinelibrary.wiley.com/doi/10.1002/cpt.1796, Wiley Online Library on [28/04/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License', metadata={'source': 'introtoML.pdf', 'page': 9}),\n",
       " Document(page_content='CLINICAL PHARMACOLOGY & THERAPEUTICS | VOLUME 107 NUMBER 4 | April 2020 881of possible effects, it leads to harder interpretation of the eventual \\nmodel. In practice, the selection of the kernel function is based on computational efficiency. Other popular kernels include linear and polynomial kernels.\\n47\\nNeural networks\\nBackground.  Neural networks constitute a collection of neurons and \\nedges, drawing its origins from circuit analysis. Different weights can be applied to each edge connecting the neurons. At each neuron, an activation function is applied to a weighed input signal to generate an output signal. A sigmoidal function is often used, consisting of a first order lowpass filter of a unit step function. Such sigmoidal function has the advantages of yielding bounded output and of being continuously differentiable, which is needed in the backward propagation step to tune the weights (parameters of the model), see steps defined in the section “Recurrent Neural Network.”\\nNeurons are further subdivided into an input layer, hidden lay -\\ner(s), and output layer, as shown in Figure 7a. The hidden layers \\nperform the layer of abstraction needed to go from the input layer to the output layer. The number of hidden layers define whether the system is a shallow learning system (with one or a few hidden layer) or deep learning (with many hidden layers). There is an in -\\nherent trade-off between the number of hidden layers and time required to train the model. For this reason, although the core concept embedded in the neural network is not a novel one, it has found a resurgence of applications due to recent advances in com -\\nputational power.\\nThe most basic type is known as feedforward neural network, as \\ninformation is just propagated from the input layer to the hidden layer(s) and finally to the output layer. The current state of the sys-tem is not defined by any past state; hence, it represents a memo -\\nryless system.\\nIn the following, illustrative examples of neural networks are \\ndescribed: recurrent neural networks, long short-term memory networks, and gated recurrent networks. Further notable neural networks that are out of scope for this article but we recommend further reading on are convolutional neural networks,\\n53 encod -\\ner-decoder networks,54,55 and generative models.56Recurrent neural network.  Recurrent neural networks are a class \\nof neural networks dedicated to time series datasets as they factor in the inherent sequential relationship observed in the data of one time point to another. It has found success in what is known in the field as sequential data , where the order or time sequence \\nof the signal plays a role, namely in natural language processing and time series forecasting. More closely related to our field of research, it has found application in predicting outcomes from electronic health records, where the richness comes inherently from the sequence correlation structure of the data to recommend swift and even anticipatory actions to be taken by the medical staff.\\n57 Rephrasing the question to solve a modeling conundrum \\nin the pharmacometrics field is only starting to emerge at the time when this paper was drafted. Tang et al . present one of the rare \\nattempts on how to use ML (here: RNNs) to characterize the PK of remifentanil and compared the results to the pharmacometrics gold-standard method NONMEM.\\n58 Although nonstandard PK \\nmodels were used for the comparison and the generalizability of the results can be challenged, Tang et al . make a valuable contribution \\nin exemplifying where RNNs could be used in pharmacometrics.\\nThe basic form of an RNN is shown in Figure 7b, where each', metadata={'source': 'introtoML.pdf', 'page': 10}),\n",
       " Document(page_content='in exemplifying where RNNs could be used in pharmacometrics.\\nThe basic form of an RNN is shown in Figure 7b, where each \\ncurrent state (at time t) is defined by a combination of the previous state of the system and the current input, which is similar to the concept of classical dynamic systems. The weights for each edge can be determined as to how far back to look into, similar to a time constant. Contrary to feedforward neural network, an identical weight is shared across in the individual neuron unit block across all the earlier discrete time steps.\\nAt the core of the RNN, it consists of an input sequence defined \\nby \\nx(t), an output sequence as defined by o(t), a hidden or system \\nstate sequence as defined by h(t), as well as a chained submodules \\nof repeated units.\\nThe steps needed to train an RNN model are as follows:\\n1. Define a network architecture and initialize the model with random weights and biases.\\n2. Perform a forward propagation to compute the estimated output.\\n3. Calculate the error at the output layer.\\nFigure 7 Neural networks. ( a) Basics of feedforward neural networks. ( b) Unfolding of recurrent neural networks. ( c) Extensions of recurrent \\nneural networks with gating units. Black square represents a delay of one discrete time step.o\\nh\\nxo(t-2 )\\nh(t-2 )\\nx(t-2)o(t-1)\\nh(t-1 )\\nx(t-1)o(t)\\nh(t)\\nx(t)FFFFF(a)\\nunfol d\\n...output\\nlaye r\\nhidden  \\nlayers\\ninpu t\\nlaye rForget  \\nGateInput  \\nGateOutput \\nGate(c) (b)\\nTUTORIAL\\n 15326535, 2020, 4, Downloaded from https://ascpt.onlinelibrary.wiley.com/doi/10.1002/cpt.1796, Wiley Online Library on [28/04/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License', metadata={'source': 'introtoML.pdf', 'page': 10}),\n",
       " Document(page_content='VOLUME 107 NUMBER 4 | April 2020 | www.cpt-journal.com 8824. Perform a backward propagation to update the weights using \\nan optimization approach.\\n5. Repeat steps 2–4 for the number of epochs (or iterations) until the loss function value is deemed minimized.\\nExtensions from this V anilla RNN were developed to address \\nthe problems of unstable gradient problem (e.g., the vanishing gradient problem and the more serious counterpart of instabil -\\nity caused by an exploding gradient). These problems at their core are due to multiplications (under the influence of numer -\\nical errors) introduced in the backward propagation in relation of the error estimates to the parameters along each layer of the neural network. In other words, the vanishing gradient causes information that needs to be captured from a time point further away from the current time and, thus, renders the model weak to capture valuable stored memory with longer time lag. In the less common event that at least one partial derivative violates the requirement for stability, translating to the state matrix of having at least one eigenvalue >\\xa01, this will lead to an exploding gradi-ent problem, a known problem in traditional dynamic system for discrete time. The remit used to address this fundamental problem will be described more in two well-known extensions of RNN (long short-term memory (LSTM) and gated recurrent network (GRU)).\\nThere has been many different variants and development in \\nRNN research, each novel method serves to address a different problem ultimately leading to the development of more robust models. For example, to circumvent the unstable gradient problem, gradient clipping of forcing the gradient to a threshold has been proposed in ref. \\n59,60, but by far the most widely accepted method \\nis the inclusion of gating units .\\nLong short-term memory and gated recurrent network.  LSTM \\nis part of a larger family of gated RNNs that retain and forget information with the introduction of gating units. More specifically, three gating units can be included in the system, as shown in Figure 7c. First, a direct copying or clearing of the \\nstate altogether can be controlled by the forget gate. A similar approach is also handled by the input gate to decide whether to include the current input signal as part of the update of the state. The amount of information to retain from the previous state signal and from the perturbation input signal is learned at each time step.\\n61 The system needs to learn long-term \\ntime dependencies by retaining information but it must also occasionally learn to clear information from its current state.\\n62 \\nConsequently, solving the vanishing and exploding gradient problems. Finally, an output gate can be introduced, although less common, as a gating mechanism to decide which output signal gets fed back to the system.\\nA simpler rendition and, thus, faster training implementation can \\nbe found in GRU . GRUs address the same problem of unstable gra -\\ndients and represent a new addition to this family of RNN exten -\\nsions. The core difference between LSTM and GRU is that the latter omits the output gate and uses simpler reset and update gates.\\n63 In \\ntheory, however, LSTM should perform better as it can up-weight or down-weigh information from longer time-distance/lag.Examples of supervised ML applications in clinical \\npharmacology\\nModels in clinical pharmacology have typically been established \\nby translating physiological and pharmacological principles to systems of differential equations and using expectation-max -\\nimization algorithms to estimate the model parameters. This mechanistically motivated approach has proven useful in many applications and is a well-established component of drug develop -\\nment programs. Potentially due to the success of these established approaches, only few examples of applying ML methods to clin -\\nical pharmacology problems exist up to now. Ryu et al . trained a', metadata={'source': 'introtoML.pdf', 'page': 11}),\n",
       " Document(page_content='ment programs. Potentially due to the success of these established approaches, only few examples of applying ML methods to clin -\\nical pharmacology problems exist up to now. Ryu et al . trained a \\ndeep neural network on a large curated database covering 192,284 drug-drug interactions in order to predict drug-drug and drug-food interactions for prescriptions, dietary recommendations, and new molecules.\\n64 Combining datasets from multiple studies to \\ncreate large databases increases the potential to use ML to tackle broad clinical pharmacology questions.\\nML has also been used to bridge drug discovery and clinical \\ndevelopment. For example, Hammann et al . were able to predict \\nincidence of adverse events from a molecule’s chemical structure using a decision tree method.\\n65 Similarly, Lancaster and Sobie im -\\nplemented SVMs to predict risk of T orsades de Pointes from in vitro  data.\\n66\\nIn the area of personalized safety, ML has been used by \\nDaunhawer et al . to personalize safety in the context of hyper -\\nbilirubinemia in neonates.67 The authors used lasso and random \\nforests to make predictions from clinical datasets. Furthermore, reinforcement learning was used by Gaweda et al . to personalize \\npharmacological anemia management.\\n68 A similar approach was \\nused to develop a “closed loop” system for glucose control by com -\\nbining a mathematical model, a glucose sensor, and a reinforcement learning model.\\n69 Chavada et al . and Hennig et al . investigated the \\nfeasibility of Bayesian feedback for dose adjustment of antibiot -\\nics.70,71 The area of personalized healthcare could greatly benefit \\nfrom using ML models that recommend dose adjustments in real time. In a recent study, an ML-type control algorithm was inte -\\ngrated with existing structural PK/PD models that are familiar to pharmacometricians and the resulting closed-loop control system was found to outperform a sensor-assisted pump.\\n69\\nMain takeaways\\n• Supervised learning methods infer models based on labeled out -\\nput-input pairs of the training dataset.\\n• Performance metrics are used to assess the classification and re -\\ngression models to avoid overfitting of the training dataset.\\n• Many supervised learning methods exist with different trade-off between interpretability and performance.\\n• RNN is a special form of neural network that represents a dy -\\nnamic system in discrete time.\\n• Examples of the applications of these supervised learning meth -\\nods in computational biology and particularly clinical pharma -\\ncology are beginning to emerge.\\nDISCUSSION\\nIn this tutorial, we have introduced some fundamental methods of ML that are likely to be of interest to the clinical pharmacology \\nTUTORIAL\\n 15326535, 2020, 4, Downloaded from https://ascpt.onlinelibrary.wiley.com/doi/10.1002/cpt.1796, Wiley Online Library on [28/04/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License', metadata={'source': 'introtoML.pdf', 'page': 11}),\n",
       " Document(page_content='CLINICAL PHARMACOLOGY & THERAPEUTICS | VOLUME 107 NUMBER 4 | April 2020 883and pharmacometrics community. Our brief introduction is sup -\\nplemented with a range of relevant references. We have provided \\ncontext by mentioning examples relevant to drug development. We conclude by summarizing how the fields of ML and clinical pharmacology are currently situated and by providing an outlook on how we expect to see further integration of the fields in the fu -\\nture. Advanced statistical methods are not new to pharmacome -\\ntricians; in fact, such methods have been used to describe PK and PD phenomena for some time. For example, Bayesian methods are a well-established component of pharmacometric approaches.\\n72,73 \\nIt seems, therefore, likely that as statistical and ML approaches be -\\ncome more established and more prominent in the pharmaceuti -\\ncal industry, pharmacometricians will be among those who take advantage of these methods. Furthermore, new opportunities to investigate other clinical questions, such as patient stratification from high-dimensional baseline characteristics, may become pos -\\nsible in clinical pharmacology using ML approaches.\\nSeveral of the examples where ML approaches have been applied \\nto clinical pharmacology questions include the integration of “clas-sical” modeling techniques, such as specifying a structural model based on mechanistic understanding, and ML approaches.\\n69–71 \\nClassical pharmacometric approaches are based on pharmacological principles that reflect hypotheses generated from the understanding of physiology and drug properties. It is unlikely that these models will be completely replaced by ML approaches in the near future. However, when the datasets and problems are more complex, many unknown influences and relationships exist and the focus is on in -\\nterpolation and fast evaluation, pharmacometrics might benefit from applying ML-type methods. Going forward, we expect that fusing this understanding with ML models could lead to very effec-tive models in the future. A recent perspective article provides more detail on applications of ML in clinical pharmacology.\\n74\\nIn the age of big data, there are many new opportunities for ML \\nin clinical pharmacology. For example, data generated from wear -\\nable devices pose new challenges on how they can be linked to PK data in the future. In addition, access to real-world data could pro -\\nvide strong evidence for covariates, supplement control datasets, and bolster models that have been trained on small datasets.\\nIn pharmacometric approaches, a predictive model is typically \\nestablished by integrating a structural model and relevant data. The structural model substantially constrains the solution space and, therefore, relatively little data are required to fit the model. On the contrary, in neural networks, model structure is not pre -\\nspecified and, thus, comparatively much more data are required for building a predictive model. It is also important to note that we are still very much at the infancy stage of understanding at which point the merger of larger data with these novel ML methods can be beneficial for performance as compared with more traditional methods. The following challenge\\n75 on time se -\\nries forecasting shows that combinations of classic statistical and ML methods produce the most accurate forecasting and, thus, suggest it as a way forward. One of the main drivers of success of the pharmacometric approaches is that the models include a thorough understanding of the processes of drug absorption, dis-tribution, metabolism, and elimination. The established models are highly predictive and, thus, find wide use in supporting drug development. Due to this success, despite the arrival of ML, clas-sical pharmacometrics approaches are not expected to decrease in importance and activity. In contrast, they can be enhanced and improved by knowledge and insight distilled by ML meth -\\nods and models.', metadata={'source': 'introtoML.pdf', 'page': 12}),\n",
       " Document(page_content='ods and models.\\nAn ongoing challenge for members of the clinical pharmacology \\ncommunity who wish to use ML methods is the inherent preva -\\nlence of longitudinal data. So far, there are many ML methods that rely on baseline features to make predictions, but relatively few ex -\\namples where longitudinal data are used.\\nOverall, we expect that there will never be a universal, one-size-\\nfits-all approach to which modelers from different fields converge. W e note that there are many areas of potential synergy where mod -\\neling fields overlap in the remit of drug development. The clinical pharmacology community will continue to base their analyses on pharmacological principles and will gradually build in new ML el -\\nements to their workflow, strengthening their models further. In addition, the clinical pharmacology community will be able to en -\\nhance the range of questions they are able to address by using ML approaches.\\nFUNDING\\nI.I.D. is a recipient of the Roche Postdoctoral Fellowship. This study is \\nfunded by F. Hoffmann-La Roche Ltd.\\nCONFLICT OF INTEREST\\nAll authors declared no competing interests for this work.\\n© 2020 The Authors. Clinical Pharmacology & Therapeutics  \\npublished by Wiley Periodicals, Inc. on behalf of American Society for \\nClinical Pharmacology and Therapeutics.\\nThis is an open access article under the terms of the Creative Commons \\nAttribution-NonCommercial-NoDerivs License, which permits use and distribution in any medium, provided the original work is properly cited, the use is non-commercial and no modifications or adaptations are made.\\n 1. Camacho, D.M., Collins, K.M., Powers, R.K., Costello, J.C. & \\nCollins, J.J. Next-generation machine learning for biological \\nnetworks. Cell  173, 1581–1592 (2018).\\n 2. Shen, D., Wu, G. & Suk, H.-I. Deep learning in medical image \\nanalysis. Annu. Rev. Biomed. Eng. 19 , 221–248 (2017).\\n 3. Rajkomar, A., Dean, J. & Kohane, I. Machine learning in medicine. \\nN. Engl. J. Med. 380 , 1347–1358 (2019).\\n 4. Kleene, S.C. Representation of Events in Nerve Nets and Finite \\nAutomata (RAND Project Air Force, Santa Monica, CA, 1951) \\n<https://apps.dtic.mil/docs/citat  ions/ADA59  6138>.\\n 5. Breiman, L. Statistical modeling: the two cultures (with comments \\nand a rejoinder by the author). Stat. Sci.  16, 199–231 (2001).\\n 6. Ribeiro, M.T., Singh, S. & Guestrin, C. \"Why should I trust you?\": \\nExplaining the predictions of any classifier. Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, San Francisco, CA , August 13–17, 2016.\\n 7. Štrumbelj, E. & Kononenko, I. Explaining prediction models and \\nindividual predictions with feature contributions. Knowl. Inf. Syst.  \\n41, 647–665 (2014).\\n 8. Lipton, Z.C. The mythos of model interpretability. ACM Queue  16, \\n31–57 (2018).\\n 9. Hastie, T., Tibshirani, R. & Friedman, J. The Elements of Statistical \\nLearning: Data Mining, Inference and Prediction  (Springer New York \\nInc., New York, NY, 2008).\\n 10. Jerez, J.M. et al. Missing data imputation using statistical and \\nmachine learning methods in a real breast cancer problem. Artif. Intell. Med.  50, 105–115 (2010).\\nTUTORIAL\\n 15326535, 2020, 4, Downloaded from https://ascpt.onlinelibrary.wiley.com/doi/10.1002/cpt.1796, Wiley Online Library on [28/04/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License', metadata={'source': 'introtoML.pdf', 'page': 12}),\n",
       " Document(page_content='VOLUME 107 NUMBER 4 | April 2020 | www.cpt-journal.com 884 11. Dorogush, A.V., Ershov, V. & Gulin, A. CatBoost: gradient boosting \\nwith categorical features support. arXiv preprint arXiv:1810.11363  \\n(2018).\\n 12. Cortes, C., Mohri, M., Riley, M., Rostamizadeh, A., Freund, Y., \\nGyörfi, L., Turán, G. & Zeugmann, T. (eds.) Sample selection bias \\ncorrection theory. In Algorithmic Learning Theory . 38–53 (Springer, \\nBerlin, Heidelberg, 2008).\\n 13. Lee, B.K., Lessler, J. & Stuart, E.A. Improving propensity score \\nweighting using machine learning. Stat. Med.  29, 337–346 \\n(2010).\\n 14. Newby, D., Freitas, A.A. & Ghafourian, T. Coping with unbalanced \\nclass data sets in oral absorption models. J. Chem. Inf. Model. 53, \\n461–474 (2013).\\n 15. Hu, L.-H., Huang, M.-W., Ke, S.-W. & Tsai, C.-F. The distance \\nfunction effect on k-nearest neighbor classification for medical datasets. Springerplus  5, 1304 (2016).\\n 16. Borozan, I., Watt, S. & Ferretti, V. Integrating alignment-based \\nand alignment-free sequence similarity measures for biological \\nsequence classification. Bioinformatics  31, 1396–1404 (2015).\\n 17. Collisson, E.A., Bailey, P., Chang, D.K. & Biankin, A.V. Molecular \\nsubtypes of pancreatic cancer. Nat. Rev. Gastroenterol. Hepatol.  \\n16, 207–220 (2019).\\n 18. Lloyd, S. Least squares quantization in PCM. IEEE Trans. Inf. \\nTheory  28, 129–137 (1982).\\n 19. Kriegel, H.-P., Kröger, P., Sander, J., Zimek, A. Density-based \\nclustering. Wiley Interdisc. Rev Data Min. Knowl. Discov. 1 , \\n231–240 (2011).\\n 20. Ester, M., Kriegel, H.-P., Sander, J. & Xu, X.A density-based \\nalgorithm for discovering clusters a density-based algorithm for discovering clusters in large spatial databases with noise. \\nProceedings of the Second International Conference on Knowledge Discovery and Data Mining. 226–231 (AAAI Press, Portland, OR, 1996).\\n 21. Zimek, A., Schubert, E. & Kriegel, H.-P. A survey on unsupervised \\noutlier detection in high-dimensional numerical data. Stat. Anal. Data Min. 5 , 363–387 (2012).\\n 22. Pearson, K. On lines and planes of closest fit to systems \\nof points in space. The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science  2, 559–572 \\n(1901).\\n 23. van der Maaten, L. & Hinton, G. Visualizing data using t-SNE. J. \\nMach. Learning Res.  9, 2579–2605 (2008).\\n 24. Becht, E. et al. Dimensionality reduction for visualizing single-cell \\ndata using UMAP. Nat. Biotechnol.  37, 38–44 (2019).\\n 25. Nguyen, L.H. & Holmes, S. Ten quick tips for effective \\ndimensionality reduction. PLoS Comput. Biol.  15, e1006907 \\n(2019).\\n 26. Wang, C., Machiraju, R. & Huang, K. Breast cancer patient \\nstratification using a molecular regularized consensus clustering \\nmethod. Methods  67, 304–312 (2014).\\n 27. Cooper, G.S., Bynum, M.L. & Somers, E.C. Recent insights in \\nthe epidemiology of autoimmune diseases: improved prevalence \\nestimates and understanding of clustering of diseases. J. \\nAutoimmun. 33 , 197–207 (2009).\\n 28. Walsh, D. & Rybicki, L. Symptom clustering in advanced cancer. \\nSupport. Care Cancer 14 , 831–836 (2006).\\n 29. Genotype-Tissue Expression (GTEx) Consortium et al. The \\ngenotype-tissue expression (GTEx) pilot analysis: multitissue gene \\nregulation in humans. Science  348, 648–660 (2015).\\n 30. Zhang, J.D., Berntenis, N., Roth, A. & Ebeling, M. Data mining \\nreveals a network of early-response genes as a consensus signature of drug-induced in vitro and in vivo toxicity. Pharmacogenomics J.  14, 208–216 (2014).\\n 31. Gemma, A. et al. Anticancer drug clustering in lung cancer based \\non gene expression profiles and sensitivity database. BMC Cancer  6, 174 (2006).\\n 32. Koch, M.A. & Waldmann, H. Protein structure similarity clustering \\nand natural product structure as guiding principles in drug \\ndiscovery. Drug Discov. Today 10 , 471–483 (2005).\\n 33. Reutlinger, M. & Schneider, G. Nonlinear dimensionality reduction \\nand mapping of compound libraries for drug discovery. J. Mol.', metadata={'source': 'introtoML.pdf', 'page': 13}),\n",
       " Document(page_content=\"discovery. Drug Discov. Today 10 , 471–483 (2005).\\n 33. Reutlinger, M. & Schneider, G. Nonlinear dimensionality reduction \\nand mapping of compound libraries for drug discovery. J. Mol. \\nGraph. Model.  34, 108–117 (2012). 34. Ezzat, A., Wu, M., Li, X.-L. & Kwoh, C.-K. Drug-target interaction \\nprediction using ensemble learning and dimensionality reduction. \\nMethods  129, 81–88 (2017).\\n 35. Nesterov, Y. Lectures on Convex Optimization. Vol. 137  (Springer, \\nBerlin, Germany, 2018).\\n 36. Cawley, G.C. & Talbot, N.L.C. On over-fitting in model selection \\nand subsequent selection bias in performance evaluation. J. \\nMach. Learn. Res. 11 , 2079–2107 (2010).\\n 37. Mitchell, T.M. Machine Learning  (McGraw-Hill Inc., New York, NY, \\n1997).\\n 38. Belson, W.A. Matching and prediction on the principle of biological \\nclassification. J. R. Stat. Soc. Ser. C Appl. Stat. 8 , 65–75 (1959).\\n 39. Krischer, J.P. An annotated bibliography of decision analytic \\napplications to health care. Oper. Res.  28, 97–113 (1980).\\n 40. Shortliffe, E.H., Buchanan, B.G. & Feigenbaum, E.A. Knowledge \\nengineering for medical decision making: A review of computer-based clinical decision aids. Proc. IEEE  67, 1207–1224 (1979).\\n 41. Bach, P.H. & Bridges, J.W. A decision tree approach for the \\napplication of drug metabolism and kinetic studies to in vivo and in vitro toxicological and pharmacological testing. Arch. Toxicol. Suppl.  8, 173–188 (1985).\\n 42. Jordan, T.J. & Reichman, L.B. Once-daily versus twice-daily \\ndosing of theophylline: a decision analysis approach to evaluating theophylline blood levels and compliance. Am. Rev. Respir. Dis. 140, 1573–1577 (1989).\\n 43. Breiman, L., Friedman, J., Olshen, R. & Stone, C. \\nClassification and regression trees. Wadsworth Int. Group 37, \\n237–251 (1984).\\n 44. Quinlan, J.R. Induction of decision trees. Mach. Learn.  1, 81–106 \\n(1986).\\n 45. Breiman, L. Random forests. Mach. Learn.  45, 5–32 (2001).\\n 46. Segal, M.R. Machine Learning Benchmarks and Random Forest \\nRegression. Technical Report, (Center for Bioinformatics & \\nMolecular Biostatistics, University of California, San Francisco, \\nCA, 2003).\\n 47. Ben-Hur, A., Ong, C.S., Sonnenburg, S., Schölkopf, B. & Rätsch, \\nG. Support vector machines and kernels for computational \\nbiology. PLoS Comput. Biol.  4, e1000173 (2008).\\n 48. Newman, A. et al. Robust enumeration of cell subsets from tissue \\nexpression profiles. Nat. Methods  12, 453–457 (2015).\\n 49. Vapnik, V. & Lerner, A. Pattern recognition using generalized \\nportrait method. Automat. Rem. Contr. 24 , 774–780 (1963).\\n 50. Smola, A.J. & Schölkopf, B. A tutorial on support vector \\nregression. Stat. Comput.  14, 199–222 (2004).\\n 51. Mercer, J. Functions of positive and negative type and their \\nconnection with the theory of integral equations. Philos. Trans. R. \\nSoc. Lond. B Bio. Sci. 415–446 , (1909).\\n 52. Schölkopf, B. & Smola, A.J. Learning With Kernels: Support Vector \\nMachines, Regularization, Optimization, and Beyond  (The MIT \\nPress, Cambridge, MA, 2002).\\n 53. Krizhevsky, A., Sutskever, I. & Hinton, G.E. Imagenet classification \\nwith deep convolutional neural networks. Advances in Neural Information Processing Systems  25, 1097–1105 (2012).\\n 54. Cho, K. et al. Learning phrase representations using RNN \\nencoder-decoder for statistical machine translation. arXiv preprint arXiv:1406.1078  (2014).\\n 55. Cho, K., Van Merriënboer, B., Bahdanau, D. & Bengio, Y.On \\nthe properties of neural machine translation: encoder-decoder approaches. arXiv preprint arXiv:1409.1259  (2014).\\n 56. Kingma, D.P.,  Mohamed, S.,  Rezende, D.J. &  Welling, M. \\nSemi-supervised learning with deep generative models. NIPS'14: Proceedings of the 27th International Conference on Neural Information Processing Systems, 2 , 3581–3589 (2014).\\n 57. Choi, E. et al. Using recurrent neural network models for early \\ndetection of heart failure onset. OUP Academic  (2016) <https://\\nacade  mic.oup.com/jamia/  artic le/24/2/361/2631499>\", metadata={'source': 'introtoML.pdf', 'page': 13}),\n",
       " Document(page_content='57. Choi, E. et al. Using recurrent neural network models for early \\ndetection of heart failure onset. OUP Academic  (2016) <https://\\nacade  mic.oup.com/jamia/  artic le/24/2/361/2631499>\\n 58. Tang, J.-T., Cao, Y., Xiao, J.-Y. & Guo, Q.-L. Predication of plasma \\nconcentration of remifentanil based on Elman neural network. J. \\nCent. South Univ. 20 , 3187–3192 (2013).\\n 59. Pascanu, R., Mikolov, T. & Bengio, Y. On the difficulty of training \\nrecurrent neural networks. International conference on machine \\nlearning, Edinburgh, June 26–July 1, 1310–1318 (2013).\\nTUTORIAL\\n 15326535, 2020, 4, Downloaded from https://ascpt.onlinelibrary.wiley.com/doi/10.1002/cpt.1796, Wiley Online Library on [28/04/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License', metadata={'source': 'introtoML.pdf', 'page': 13}),\n",
       " Document(page_content='CLINICAL PHARMACOLOGY & THERAPEUTICS | VOLUME 107 NUMBER 4 | April 2020 885 60. Bengio, Y., Boulanger-Lewandowski, N. & Pascanu, R. Advances in \\noptimizing recurrent networks. IEEE International Conference on \\nAcoustics, Speech and Signal Processing, Kyoto, March 25–30, \\n8624–8628 (2012).\\n 61. Hochreiter, S. & Schmidhuber, J. Long short-term memory. Neural \\nComput.  9, 1735–1780 (1997).\\n 62. Goodfellow, I., Bengio, Y. & Courville, A. Deep Learning  (MIT Press, \\nCambridge, MA, 2016) <http://www.deepl  earni ngbook.org>\\n 63. Chung, J., Gulcehre, C., Cho, K. & Bengio, Y. Empirical evaluation of \\ngated recurrent neural networks on sequence modeling. Workshop \\non Deep Learning in NIPS, Montreal, December 8–13, (2014).\\n 64. Ryu, J.Y., Kim, H.U. & Lee, S.Y. Deep learning improves prediction \\nof drugdrug and drugfood interactions. Proc. Natl. Acad. Sci. 115 , \\nE4304–E4311 (2018).\\n 65. Hammann, F., Gutmann, H., Vogt, N., Helma, C. & Drewe, \\nJ. Prediction of adverse drug reactions using decision tree \\nmodeling. Clin. Pharmacol. Ther.  88, 52–59 (2010).\\n 66. Lancaster, M.C. & Sobie, E. Improved prediction of drug-induced \\ntorsades de pointes through simulations of dynamics and machine learning algorithms. Clin. Pharmacol. Ther.  100, 371–379 (2016).\\n 67. Daunhawer, I. et al. Enhanced early prediction of clinically relevant \\nneonatal hyperbilirubinemia with machine learning. Pediatr. Res.  \\n86, 122 (2019).\\n 68. Gaweda, A.E. et al. Individualization of pharmacological anemia \\nmanagement using reinforcement learning. Neural Networks  18, \\n826–834 (2005). 69. Benhamou, P.-Y. et al. Closed-loop insulin delivery in adults with \\ntype 1 diabetes in real-life conditions: a 12-week multicentre, \\nopen-label randomised controlled crossover trial. Lancet Dig. \\nHealth  1, e17–e25 (2019).\\n 70. Chavada, R., Ghosh, N., Sandaradura, I., Maley, M. & Van Hal, \\nS.J. Establishment of an AUC\\n0-24 threshold for nephrotoxicity is \\na step towards individualized vancomycin dosing for methicillin-\\nresistant staphylococcus aureus bacteremia. Antimicrob. Agents \\nChemother.  61, e02535–16 (2017).\\n 71. Hennig, S., Holthouse, F. & Staatz, C.E. Comparing dosage \\nadjustment methods for once-daily tobramycin in paediatric and \\nadolescent patients with cystic fibrosis. Clin. Pharmacokinet.  54, \\n409–421 (2015).\\n 72. Dansirikul, C., Morris, R.G., Tett, S.E. & Duffull, S.B. A Bayesian \\napproach for population pharmacokinetic modelling of sirolimus. Br. J. Clin. Pharmacol.  62, 420–434 (2006).\\n 73. Lunn, D.J., Best, N., Thomas, A., Wakefield, J. & Spiegelhalter, D. \\nBayesian analysis of population PK/PD models: general concepts \\nand software. J. Pharmacokinet. Pharmacodyn.  29, 271–307 \\n(2002).\\n 74. Hutchinson, L. et al. Models and machines: how deep learning will \\ntake clinical pharmacology to the next level. CPT Pharmacomet. Syst. Pharmacol.  8, 131–134 (2019).\\n 75. Makridakis, S., Spiliotis, E. & Assimakopoulos, V. The M4 \\ncompetition: results, findings, conclusion and way forward. Int. J. Forecast.  34, 802–808 (2018).\\nTUTORIAL\\n 15326535, 2020, 4, Downloaded from https://ascpt.onlinelibrary.wiley.com/doi/10.1002/cpt.1796, Wiley Online Library on [28/04/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License', metadata={'source': 'introtoML.pdf', 'page': 14})]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader  = PyPDFLoader(\"introtoML.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the question based on the context below. If you can't \n",
      "answer the question, reply \"I don't know\".\n",
      "\n",
      "Context: Here is some context\n",
      "\n",
      "Question: Here is a question\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Prompt Engineering and Template \n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the question based on the context below. If you can't \n",
    "answer the question, reply \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "print(prompt.format(context=\"Here is some context\", question=\"Here is a question\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Based on the context you provided, your name is Satya.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Testing\n",
    "\n",
    "# chain = prompt | model\n",
    "\n",
    "# chain.invoke(\n",
    "#     {\n",
    "#         \"context\": \"The name that was given to me was Satya\",\n",
    "#         \"question\": \"What is my name\"\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "vectorstore = DocArrayInMemorySearch.from_documents(pages, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold validation is a technique used in machine learning to evaluate the performance of a model by dividing the available data into a fixed number of folds, training the model on one fold and evaluating its performance on another fold. This process is repeated for all possible combinations of folds, and the average performance is calculated across all folds.\n",
      "\n",
      "The purpose of k-fold validation is to reduce the risk of overfitting, which occurs when a model is trained too well on a limited portion of the training data and performs poorly on new, unseen data. By training and evaluating the model on multiple folds, k-fold validation provides a more robust estimate of the model's generalization performance.\n",
      "\n",
      "The steps involved in k-fold validation are as follows:\n",
      "\n",
      "1. Divide the available data into a fixed number of folds (k).\n",
      "2. Randomly select one fold for training the model, and the remaining k-1 folds for evaluating the model's performance.\n",
      "3. Train the model on the training fold and evaluate its performance on the evaluation folds.\n",
      "4. Repeat steps 2-3 for all possible combinations of folds.\n",
      "5. Calculate the average performance across all folds.\n",
      "\n",
      "The value of k is a hyperparameter that needs to be chosen carefully. A common choice is k=5 or k=10, but it can vary depending on the complexity of the problem and the size of the dataset.\n",
      "\n",
      "K-fold validation is widely used in machine learning to evaluate the performance of models in various applications, such as image classification, speech recognition, and natural language processing.\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "# Create a retriever from the vectorstore\n",
    "retriver = vectorstore.as_retriever()\n",
    "\n",
    "chain = (\n",
    "    \n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriver,\n",
    "        \"question\": itemgetter(\"question\")\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    ")\n",
    "\n",
    "print(chain.invoke({\"question\": \"What is k-fold validation\"}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
